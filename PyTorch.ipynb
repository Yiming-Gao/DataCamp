{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Chapter-3-Convolutional-Neural-Networks-(CNNs)\" data-toc-modified-id=\"Chapter-3-Convolutional-Neural-Networks-(CNNs)-1\">Chapter 3 Convolutional Neural Networks (CNNs)</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Convolution-operator---OOP-way\" data-toc-modified-id=\"Convolution-operator---OOP-way-1.0.1\">Convolution operator - OOP way</a></span></li><li><span><a href=\"#Convolution-operator---Functional-way\" data-toc-modified-id=\"Convolution-operator---Functional-way-1.0.2\">Convolution operator - Functional way</a></span></li><li><span><a href=\"#Max-pooling-operator\" data-toc-modified-id=\"Max-pooling-operator-1.0.3\">Max-pooling operator</a></span></li><li><span><a href=\"#Your-first-CNN---init-method\" data-toc-modified-id=\"Your-first-CNN---init-method-1.0.4\">Your first CNN - <strong>init</strong> method</a></span></li><li><span><a href=\"#Your-first-CNN---forward()-method\" data-toc-modified-id=\"Your-first-CNN---forward()-method-1.0.5\">Your first CNN - forward() method</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3 Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolution operator - OOP way\n",
    "- in_channels (int) - Number of channels in input\n",
    "- out_channels (int) - Number of channels produced by the convolution\n",
    "- kernel_size (int or tuple) - Size of the convolving kernel\n",
    "- stride(int or tuple, optional) - Stride of the convolution. Default: 1\n",
    "- padding (int or tuple, optional) - Zero-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# create 10 images with shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# build 6 conv filters of size (3, 3) with stride set to 1 and padding set to 1\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with filters\n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolution operator - Functional way\n",
    "- input – input tensor of shape (minibatch×in_channels×iH×iW)\n",
    "- weight – lters of shape (out_channels×in_channels×kH×kW)\n",
    "- stride – the stride ofthe convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1\n",
    "- padding - – implicit zero paddings on both sides of the input.Can be a single number or a tuple (padH, padW). Default: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Create 10 random images with shape (1, 28, 28)\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters with shape (1, 3, 3)\n",
    "filters = torch.rand(6, 1, 3, 3)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride = 1, padding=1)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max-pooling operator\n",
    "\n",
    "The convolutions are used to extract features from the image, while the pooling is a way of feature selection, choosing the most dominant features from the image, or combining different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6571, 0.9306, 0.5576],\n",
      "          [0.5193, 0.7947, 0.8003],\n",
      "          [0.7877, 0.9205, 0.7234]]]])\n",
      "tensor([[[[0.6571, 0.9306, 0.5576],\n",
      "          [0.5193, 0.7947, 0.8003],\n",
      "          [0.7877, 0.9205, 0.7234]]]])\n"
     ]
    }
   ],
   "source": [
    "# Build a pooling operator with size `2`.\n",
    "im = torch.rand(1, 1, 6, 6)\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = max_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3073, 0.5481, 0.4819],\n",
      "          [0.3767, 0.4234, 0.5605],\n",
      "          [0.6687, 0.5435, 0.6187]]]])\n",
      "tensor([[[[0.3073, 0.5481, 0.4819],\n",
      "          [0.3767, 0.4234, 0.5605],\n",
      "          [0.6687, 0.5435, 0.6187]]]])\n"
     ]
    }
   ],
   "source": [
    "# Build a pooling operator with size `2`.\n",
    "avg_pooling = torch.nn.AvgPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = avg_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your first CNN - __init__ method\n",
    "You're going to use the MNIST dataset as the dataset, which is made of handwritten digits from 0 to 9 (28* 28）. The convolutional neural network is going to have 2 convolutional layers, each followed by a ReLU nonlinearity, and a fully connected layer. Remember that each pooling layer halves both the height and the width of the image, so by using 2 pooling layers, the height and width are 1/4 of the original sizes.\n",
    "\n",
    "For the moment, you are going to implement the __init__ method of the net. In the next exercise, you will implement the .forward() method.\n",
    "\n",
    "*Note: We need 2 pooling layers, but we only need to instantiate a pooling layer once, because each pooling layer will have the same configuration.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=True)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your first CNN - forward() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "\n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
